{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 02 - Modeling\n\nThis notebook is like a place holder or sample for what your are to do on the EDA. Edit as neccessary:\n- Loads the cleaned dataset saved by the EDA notebook\n- Prepares preprocessing pipelines\n- Trains baseline models (Logistic Regression, Random Forest, XGBoost)\n- Handles class imbalance (class weights and SMOTE)\n- Uses Optuna to tune an XGBoost model\n- Evaluates models (ROC, PR, confusion matrix) and saves plots to `images/`\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Standard imports\n", "import os\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.impute import SimpleImputer\n", "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, classification_report, RocCurveDisplay, PrecisionRecallDisplay\n", "from imblearn.over_sampling import SMOTE\n", "from imblearn.pipeline import Pipeline as ImbPipeline\n", "import joblib\n", "\n", "sns.set(style='whitegrid')\n", "%matplotlib inline\n", "\n", "CLEAN_PATH = '/mnt/data/heart-disease-project/data/processed/heart_clean.csv'\n", "IMAGES_DIR = os.path.join('/mnt/data/heart-disease-project', 'images')\n", "os.makedirs(IMAGES_DIR, exist_ok=True)\n", "print('Images will be saved to:', IMAGES_DIR)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Load cleaned data\n", "df = pd.read_csv(CLEAN_PATH)\n", "print('Loaded shape:', df.shape)\n", "display(df.head())\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2. Prepare features and target\n", "TARGET = 'target'\n", "if TARGET not in df.columns:\n", "    raise KeyError('Target column not found in cleaned data.')\n", "X = df.drop(columns=[TARGET])\n", "y = df[TARGET]\n", "\n", "# Identify numeric and categorical columns simply\n", "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n", "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n", "print('Numeric cols:', num_cols)\n", "print('Categorical cols:', cat_cols)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Train/test split\n", "We keep a held-out test set for final evaluation.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n", "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Preprocessing pipelines\n", "Numeric: median imputation + standard scaling. Categorical: mode imputation + one-hot encoding.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import OrdinalEncoder\n", "num_pipeline = Pipeline([\n", "    ('imputer', SimpleImputer(strategy='median')),\n", "    ('scaler', StandardScaler())\n", "])\n", "cat_pipeline = Pipeline([\n", "    ('imputer', SimpleImputer(strategy='most_frequent')),\n", "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n", "])\n", "preprocessor = ColumnTransformer([\n", "    ('num', num_pipeline, num_cols),\n", "    ('cat', cat_pipeline, cat_cols)\n", "])\n", "print('Preprocessor ready')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Baseline models\n", "We'll train Logistic Regression (with class weight) and Random Forest. We'll also try a SMOTE pipeline.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Logistic Regression with class weighting\n", "lr_pipe = Pipeline([\n", "    ('pre', preprocessor),\n", "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n", "])\n", "lr_pipe.fit(X_train, y_train)\n", "lr_probs = lr_pipe.predict_proba(X_test)[:,1]\n", "print('Logistic AUC:', roc_auc_score(y_test, lr_probs))\n", "# Random Forest without SMOTE\n", "rf_pipe = Pipeline([\n", "    ('pre', preprocessor),\n", "    ('clf', RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced'))\n", "])\n", "rf_pipe.fit(X_train, y_train)\n", "rf_probs = rf_pipe.predict_proba(X_test)[:,1]\n", "print('Random Forest AUC:', roc_auc_score(y_test, rf_probs))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. SMOTE pipeline (oversampling) + Random Forest\n", "SMOTE operates only on numeric arrays; using imbalanced-learn's pipeline simplifies this.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["smote = SMOTE(random_state=42)\n", "smote_pipe = ImbPipeline([\n", "    ('pre', preprocessor),\n", "    ('smote', smote),\n", "    ('clf', RandomForestClassifier(n_estimators=200, random_state=42))\n", "])\n", "smote_pipe.fit(X_train, y_train)\n", "smote_probs = smote_pipe.predict_proba(X_test)[:,1]\n", "print('SMOTE + RF AUC:', roc_auc_score(y_test, smote_probs))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Evaluate and plot ROC and PR curves for the models\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = {\n", "    'Logistic': (lr_pipe, lr_probs),\n", "    'RandomForest': (rf_pipe, rf_probs),\n", "    'SMOTE_RandomForest': (smote_pipe, smote_probs)\n", "}\n", "plt.figure(figsize=(8,6))\n", "for name, (m, probs) in models.items():\n", "    fpr = np.nan\n", "    try:\n", "        from sklearn.metrics import roc_curve\n", "        fpr, tpr, _ = roc_curve(y_test, probs)\n", "        roc_auc = auc(fpr, tpr)\n", "        plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n", "    except Exception as e:\n", "        print('Could not plot ROC for', name, e)\n", "plt.plot([0,1],[0,1],'k--')\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curves')\n", "plt.legend()\n", "fn = os.path.join(IMAGES_DIR, 'roc_curves.png')\n", "plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "plt.show()\n", "\n", "# Precision-Recall\n", "plt.figure(figsize=(8,6))\n", "for name, (m, probs) in models.items():\n", "    try:\n", "        precision, recall, _ = precision_recall_curve(y_test, probs)\n", "        pr_auc = auc(recall, precision)\n", "        plt.plot(recall, precision, label=f\"{name} (PR-AUC={pr_auc:.3f})\")\n", "    except Exception as e:\n", "        print('Could not plot PR for', name, e)\n", "plt.xlabel('Recall')\n", "plt.ylabel('Precision')\n", "plt.title('Precision-Recall Curves')\n", "plt.legend()\n", "fn = os.path.join(IMAGES_DIR, 'pr_curves.png')\n", "plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Confusion matrix & classification report for the best model (by AUC)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["aucs = {name: roc_auc_score(y_test, probs) for name, (m, probs) in models.items()}\n", "best_name = max(aucs, key=aucs.get)\n", "print('AUCs:', aucs)\n", "print('Best model by AUC:', best_name)\n", "best_model = models[best_name][0]\n", "best_probs = models[best_name][1]\n", "best_preds = (best_probs >= 0.5).astype(int)\n", "cm = confusion_matrix(y_test, best_preds)\n", "print('Confusion matrix:\\n', cm)\n", "print('\\nClassification report:')\n", "print(classification_report(y_test, best_preds))\n", "plt.figure(figsize=(5,4))\n", "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n", "plt.xlabel('Predicted')\n", "plt.ylabel('Actual')\n", "plt.title(f'Confusion Matrix - {best_name}')\n", "fn = os.path.join(IMAGES_DIR, f'confusion_matrix_{best_name}.png')\n", "plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Hyperparameter tuning with Optuna for XGBoost\n", "We will run a simple Optuna search to maximize cross-validated AUC. This is beginner-friendly but still powerful.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import optuna\n", "from xgboost import XGBClassifier\n", "from sklearn.model_selection import cross_val_score\n", "\n", "def objective(trial):\n", "    params = {\n", "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n", "        'max_depth': trial.suggest_int('max_depth', 2, 8),\n", "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n", "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n", "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n", "        'use_label_encoder': False,\n", "        'eval_metric': 'logloss',\n", "        'random_state': 42\n", "    }\n", "    model = Pipeline([\n", "        ('pre', preprocessor),\n", "        ('clf', XGBClassifier(**params))\n", "    ])\n", "    # cross-validated AUC (stratified)\n", "    scores = cross_val_score(model, X_train, y_train, cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=42), scoring='roc_auc')\n", "    return float(np.mean(scores))\n", "\n", "study = optuna.create_study(direction='maximize')\n", "study.optimize(objective, n_trials=25)\n", "print('Best trial:')\n", "print(study.best_trial.params)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train a final XGBoost model with the best params\n", "best_params = study.best_trial.params\n", "best_params.update({'use_label_encoder': False, 'eval_metric': 'logloss', 'random_state': 42})\n", "final_xgb = Pipeline([\n", "    ('pre', preprocessor),\n", "    ('clf', XGBClassifier(**best_params))\n", "])\n", "final_xgb.fit(X_train, y_train)\n", "xgb_probs = final_xgb.predict_proba(X_test)[:,1]\n", "print('Final XGB AUC:', roc_auc_score(y_test, xgb_probs))\n", "# Save model\n", "joblib.dump(final_xgb, os.path.join('/mnt/data/heart-disease-project', 'models', 'final_xgb.pkl'))\n", "print('Saved final model (if models/ directory exists)')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 10. Compare final XGBoost to previous best and save results\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["finals = {\n", "    'XGBoost_Optuna': (final_xgb, xgb_probs)\n", "}\n", "all_models = {**models, **finals}\n", "for name, (m, probs) in all_models.items():\n", "    try:\n", "        r, p = precision_recall_curve(y_test, probs)\n", "        print(f\"{name}: AUC={roc_auc_score(y_test, probs):.3f}, PR-AUC={auc(p, r):.3f}\")\n", "    except Exception as e:\n", "        print('Skipped metrics for', name, e)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save a simple CSV of model scores\n", "scores = []\n", "for name, (m, probs) in all_models.items():\n", "    try:\n", "        scores.append({'model': name, 'auc': roc_auc_score(y_test, probs)})\n", "    except:\n", "        pass\n", "scores_df = pd.DataFrame(scores).sort_values('auc', ascending=False)\n", "scores_df.to_csv(os.path.join('/mnt/data/heart-disease-project', 'reports', 'model_scores.csv'), index=False)\n", "display(scores_df)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 11. Save ROC curve for final XGBoost\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import roc_curve\n", "fpr, tpr, _ = roc_curve(y_test, xgb_probs)\n", "plt.figure(figsize=(6,5))\n", "plt.plot(fpr, tpr, label=f'XGBoost (AUC={roc_auc_score(y_test, xgb_probs):.3f})')\n", "plt.plot([0,1],[0,1],'k--')\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Final XGBoost ROC')\n", "plt.legend()\n", "fn = os.path.join(IMAGES_DIR, 'final_xgb_roc.png')\n", "plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 12. Save Precision-Recall for final XGBoost\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["precision, recall, _ = precision_recall_curve(y_test, xgb_probs)\n", "plt.figure(figsize=(6,5))\n", "plt.plot(recall, precision, label=f'XGBoost (PR-AUC={auc(recall, precision):.3f})')\n", "plt.xlabel('Recall')\n", "plt.ylabel('Precision')\n", "plt.title('Final XGBoost Precision-Recall')\n", "plt.legend()\n", "fn = os.path.join(IMAGES_DIR, 'final_xgb_pr.png')\n", "plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 13. Feature importance (from XGBoost) \u2014 simple approach\n", "We will extract feature names after preprocessing by applying the preprocessor to a sample and then retrieving feature names.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_feature_names(column_transformer):\n", "    \"\"\"Utility to get feature names from a ColumnTransformer (works for our simple pipelines).\"\"\"\n", "    out = []\n", "    for name, trans, cols in column_transformer.transformers:\n", "        if name == 'remainder':\n", "            continue\n", "        if hasattr(trans, 'named_steps') and 'ohe' in trans.named_steps:\n", "            ohe = trans.named_steps['ohe']\n", "            names = list(ohe.get_feature_names_out(cols))\n", "            out.extend(names)\n", "        else:\n", "            out.extend(cols)\n", "    return out\n", "\n", "feat_names = get_feature_names(preprocessor)\n", "try:\n", "    booster = final_xgb.named_steps['clf']\n", "    # xgboost feature importance uses original feature indices, but with pipeline we have transformed features\n", "    importances = booster.feature_importances_\n", "    fi_df = pd.DataFrame({'feature': feat_names, 'importance': importances})\n", "    fi_df = fi_df.sort_values('importance', ascending=False).head(20)\n", "    plt.figure(figsize=(8,6))\n", "    sns.barplot(x='importance', y='feature', data=fi_df)\n", "    plt.title('Top 20 feature importances (XGBoost)')\n", "    fn = os.path.join(IMAGES_DIR, 'xgb_feature_importance.png')\n", "    plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "    plt.show()\n", "except Exception as e:\n", "    print('Could not compute feature importances:', e)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 14. Save final model and report\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.makedirs(os.path.join(base, 'models'), exist_ok=True)\n", "joblib.dump(final_xgb, os.path.join(base, 'models', 'final_xgb_optuna.pkl'))\n", "print('Saved final model to models/final_xgb_optuna.pkl')\n", "print('Modeling notebook complete. Review images in images/ and model scores in reports/model_scores.csv')\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}
