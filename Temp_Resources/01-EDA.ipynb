{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 01 - Exploratory Data Analysis (EDA)\n", "\n", "This notebook is like a place holder or sample for what your are to do on the EDA. Edit as neccessary:\n", "- Loads `heart.xls` from `/mnt/data`\n", "- Cleans and summarizes the dataset\n", "- Produces visualizations (displayed inline) and saves them to `images/`\n", "- Performs simple statistical tests (t-test for numeric vs target, chi-square for categorical vs target)\n", "- Prints short, automatic insights after each analysis step\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Standard imports\n", "import os\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from scipy import stats\n", "import statsmodels.api as sm\n", "from IPython.display import display\n", "\n", "# Make plots look nicer\n", "%matplotlib inline\n", "sns.set(style='whitegrid')\n", "\n", "# Paths\n", "DATA_PATH = '/mnt/data/heart.xls'\n", "IMAGES_DIR = os.path.join('..', 'images') if os.getcwd().endswith('notebooks') else os.path.join('/mnt/data/heart-disease-project', 'images')\n", "os.makedirs(IMAGES_DIR, exist_ok=True)\n", "print('Images will be saved to:', IMAGES_DIR)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Load the data\n", "df = pd.read_excel(DATA_PATH)\n", "print('Initial shape:', df.shape)\n", "display(df.head())\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2. Basic cleaning function (lowercase cols, strip whitespace, replace empty strings)\n", "def basic_clean(df):\n", "    df = df.copy()\n", "    df.columns = [str(c).strip().lower().replace(' ', '_') for c in df.columns]\n", "    df = df.drop_duplicates()\n", "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n", "    return df\n", "\n", "df = basic_clean(df)\n", "print('After basic cleaning shape:', df.shape)\n", "display(df.head())\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Ensure target exists and is binary\n", "if 'target' not in df.columns:\n", "    raise KeyError(\"The dataset must contain a 'target' column with 0/1 values indicating heart disease.\")\n", "print('Target unique values:', df['target'].unique())\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Quick summary & missingness\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["display(df.info())\n", "display(df.describe(include='all').T)\n", "\n", "# Missing values summary\n", "missing = df.isnull().sum().sort_values(ascending=False)\n", "missing = missing[missing>0]\n", "print('\\nColumns with missing values:\\n')\n", "print(missing)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Class distribution (target)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax = df['target'].value_counts().plot(kind='bar')\n", "ax.set_xticklabels(['No Disease (0)','Disease (1)'])\n", "ax.set_ylabel('Count')\n", "ax.set_title('Target class distribution')\n", "plt.tight_layout()\n", "fn = os.path.join(IMAGES_DIR, 'target_distribution.png')\n", "plt.savefig(fn, dpi=150)\n", "plt.show()\n", "print('\\nAuto-insight:')\n", "counts = df['target'].value_counts()\n", "if counts.shape[0]==2:\n", "    pct = counts.iloc[1] / counts.sum()\n", "    print(f\"Proportion with heart disease: {pct:.2%} (class=1). This indicates whether class imbalance handling may be needed.\")\n", "else:\n", "    print('Target is not binary or unexpected unique values.')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Identify numeric and categorical columns\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n", "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n", "print('Numeric columns:', num_cols)\n", "print('Categorical columns:', cat_cols)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Univariate analysis \u2014 numeric features\n", "For each numeric feature we will plot a histogram and boxplot, save them, and compute skewness."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for col in num_cols:\n", "    fig, axes = plt.subplots(1,2, figsize=(12,4))\n", "    sns.histplot(df[col].dropna(), kde=True, ax=axes[0])\n", "    axes[0].set_title(f'Histogram of {col}')\n", "    sns.boxplot(x=df[col], ax=axes[1])\n", "    axes[1].set_title(f'Boxplot of {col}')\n", "    plt.tight_layout()\n", "    fn = os.path.join(IMAGES_DIR, f'{col}_hist_box.png')\n", "    plt.savefig(fn, dpi=150)\n", "    plt.show()\n", "    skew = df[col].skew()\n", "    print(f\"{col} \u2014 skewness: {skew:.2f}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Bivariate analysis \u2014 numeric vs target\n", "Compare distributions of numeric features grouped by `target` and run t-tests (or Mann-Whitney if non-normal).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.stats import ttest_ind, mannwhitneyu\n", "\n", "for col in num_cols:\n", "    data0 = df[df['target']==0][col].dropna()\n", "    data1 = df[df['target']==1][col].dropna()\n", "    # plot\n", "    plt.figure(figsize=(6,4))\n", "    sns.boxplot(x='target', y=col, data=df)\n", "    plt.title(f'{col} by target')\n", "    fn = os.path.join(IMAGES_DIR, f'{col}_by_target_box.png')\n", "    plt.savefig(fn, dpi=150)\n", "    plt.show()\n", "    # choose test based on normality (Shapiro) and sample size\n", "    use_mw = False\n", "    try:\n", "        if len(data0) >= 3 and len(data1) >= 3:\n", "            p0 = stats.shapiro(data0.sample(min(5000, len(data0))))[1] if len(data0) <= 5000 else 1.0\n", "            p1 = stats.shapiro(data1.sample(min(5000, len(data1))))[1] if len(data1) <= 5000 else 1.0\n", "            if p0 < 0.05 or p1 < 0.05:\n", "                use_mw = True\n", "    except Exception:\n", "        use_mw = True\n", "    if use_mw:\n", "        stat, p = mannwhitneyu(data0, data1, alternative='two-sided')\n", "        test_name = 'Mann-Whitney U'\n", "    else:\n", "        stat, p = ttest_ind(data0, data1, nan_policy='omit')\n", "        test_name = 'T-test'\n", "    print(f\"{col}: {test_name} p-value = {p:.4f}\")\n", "    if p < 0.05:\n", "        print(f\"  -> Auto-insight: Significant difference in {col} between classes (p<{0.05}).\")\n", "    else:\n", "        print(f\"  -> Auto-insight: No significant difference detected for {col} (p={p:.3f}).\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Categorical features \u2014 counts and chi-square tests\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.stats import chi2_contingency\n", "if len(cat_cols)==0:\n", "    print('No categorical columns detected (object/category). If some categorical variables are numeric-coded, consider converting them.')\n", "for col in cat_cols:\n", "    print('\\nColumn:', col)\n", "    display(pd.crosstab(df[col], df['target']))\n", "    try:\n", "        table = pd.crosstab(df[col], df['target'])\n", "        if table.size == 0:\n", "            continue\n", "        chi2, p, dof, ex = chi2_contingency(table.fillna(0))\n", "        print(f'Chi-square p-value = {p:.4f}')\n", "        if p < 0.05:\n", "            print('  -> Auto-insight: There is a significant association between', col, 'and target (p<0.05).')\n", "        else:\n", "            print('  -> Auto-insight: No significant association detected (p>=0.05).')\n", "    except Exception as e:\n", "        print('Could not run chi-square test:', e)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Correlation matrix (numeric features)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["corr = df[num_cols].corr()\n", "plt.figure(figsize=(10,8))\n", "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n", "plt.title('Correlation matrix (numeric features)')\n", "fn = os.path.join(IMAGES_DIR, 'correlation_matrix.png')\n", "plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 10. Correlation of features with target (point-biserial for numeric)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.stats import pointbiserialr\n", "corrs = []\n", "for col in num_cols:\n", "    try:\n", "        r, p = pointbiserialr(df['target'].fillna(0), df[col].fillna(df[col].median()))\n", "        corrs.append({'feature': col, 'r': r, 'p': p})\n", "    except Exception as e:\n", "        pass\n", "corr_df = pd.DataFrame(corrs).sort_values('r', key=abs, ascending=False)\n", "display(corr_df)\n", "plt.figure(figsize=(6,4))\n", "sns.barplot(x='r', y='feature', data=corr_df)\n", "plt.title('Point-biserial correlation with target')\n", "fn = os.path.join(IMAGES_DIR, 'feature_target_correlation.png')\n", "plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "plt.show()\n", "print('\\nAuto-insight: Features with largest absolute correlation (top 5):')\n", "print(corr_df.head(5).to_string(index=False))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 11. Simple pairwise plots for top features\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["top_feats = corr_df['feature'].head(4).tolist()\n", "if len(top_feats) >= 2:\n", "    sns.pairplot(df[top_feats + ['target']].dropna(), hue='target', corner=True)\n", "    fn = os.path.join(IMAGES_DIR, 'pairplot_top_features.png')\n", "    plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "    plt.show()\n", "else:\n", "    print('Not enough top numeric features for pairplot.')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 12. Outlier detection (simple IQR method) and counts\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["outlier_counts = {}\n", "for col in num_cols:\n", "    q1 = df[col].quantile(0.25)\n", "    q3 = df[col].quantile(0.75)\n", "    iqr = q3 - q1\n", "    lower = q1 - 1.5 * iqr\n", "    upper = q3 + 1.5 * iqr\n", "    oc = df[(df[col] < lower) | (df[col] > upper)].shape[0]\n", "    outlier_counts[col] = oc\n", "outlier_df = pd.DataFrame.from_dict(outlier_counts, orient='index', columns=['outlier_count']).sort_values('outlier_count', ascending=False)\n", "display(outlier_df)\n", "print('\\nAuto-insight: Columns with many outliers may need robust scaling or capping before modeling.')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 13. Missingness visualization (simple)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ms = df.isnull().sum()\n", "if ms.sum() == 0:\n", "    print('No missing values detected in the dataset.')\n", "else:\n", "    ms = ms[ms>0].sort_values(ascending=False)\n", "    ms.plot.barh(figsize=(6, max(3, len(ms)*0.4)))\n", "    plt.title('Missing values per column')\n", "    fn = os.path.join(IMAGES_DIR, 'missing_values.png')\n", "    plt.savefig(fn, dpi=150, bbox_inches='tight')\n", "    plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 14. Save a cleaned version of the dataset for modeling\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clean_path = os.path.join('/mnt/data/heart-disease-project', 'data', 'processed', 'heart_clean.csv')\n", "df.to_csv(clean_path, index=False)\n", "print('Saved cleaned data to:', clean_path)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 15. Final auto-summary of EDA\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('--- EDA SUMMARY ---')\n", "print(f'Total rows: {df.shape[0]}, Total columns: {df.shape[1]}')\n", "print('\\nTop numeric features correlated with target:')\n", "display(corr_df.head(10))\n", "print('\\nColumns with missing values:')\n", "display(df.isnull().sum()[df.isnull().sum()>0])\n", "print('\\nColumns with most outliers:')\n", "display(outlier_df.head(10))\n", "print('\\nRecommendations:')\n", "print(' - Handle class imbalance if disease prevalence is low (resampling or class weights).')\n", "print(' - Consider log-transform or robust scaling for skewed features.')\n", "print(' - Impute missing values (median for numeric, mode for categorical) or use model-based imputers.')\n", "print(' - Use SHAP/feature importance after modeling to get clinical explanations.')\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}
